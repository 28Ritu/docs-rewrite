---
ID: 33144
post_title: >
  Privacy and Machine Learning | Our Open
  Data Set and Opt-In Feature
author: Alyx Horace
post_excerpt: ""
layout: post
permalink: >
  http://mycroft.ai/blog/privacy-machine-learning-open-data-set-opt-feature/
published: true
post_date: 2017-11-21 07:57:58
---
[vc_row type="in_container" full_screen_row_position="middle" scene_position="center" text_color="dark" text_align="left" overlay_strength="0.3"][vc_column column_padding="no-extra-padding" column_padding_position="all" background_color_opacity="1" background_hover_color_opacity="1" column_shadow="none" width="1/1" tablet_text_alignment="default" phone_text_alignment="default" column_border_width="none" column_border_style="solid"][divider line_type="No Line"][vc_column_text]
<h2><span style="font-weight: 400;">We’re living through a paradigm shift in computing. </span></h2>
<span style="font-weight: 400;">We’re living through yet another paradigm shift in computing.   For the most challenging problems facing computer science traditional software development is being supplanted by machine learning.  Machine learning is a programming technique that allows algorithms to become more accurate at predicting outcomes without being explicitly programmed.</span> <span style="font-weight: 400;">Instead, data is used to present examples to the learning algorithm -- much like a child is taught by being told something over and over again.  Teaching machines also relies on training data - lots and lots of it.</span>

&nbsp;
<h2></h2>
<h2></h2>
<h2>How much data do we need?</h2>
<span style="font-weight: 400;">To give you an idea of the data needs, let’s look at a key voice technologies.  Speech To Text (STT) can be tackled with a machine learning approach.  Estimates and experiments suggest that approximately 10,000 hours of audio is required to get a decent STT engine.  That is the equivalent of nearly 5 years of someone talking 40 hours a week.</span>

<span style="font-weight: 400;">Though many of the machine learning frameworks are starting to be released as open source the </span><i><span style="font-weight: 400;">data </span></i><span style="font-weight: 400;">underpinning them is </span><i><span style="font-weight: 400;">not </span></i><span style="font-weight: 400;">being released.  Without data a learning framework cannot solve complex problems.  This means that companies without access to LOTS of data are getting left behind.</span>

&nbsp;
<h3>How's everyone else getting their hands on adequate data?</h3>
<span style="font-weight: 400;">There are currently a handful of organizations who have billions of customers who have agreed to allow their data be used.  This agreement was necessary to make use of the company’s services.  This is what’s in those “Terms of Service” notices everyone routinely accepts without careful reading.  Typically, the only option for a user who wishes for privacy is to simply stop using these services.  This is true of Amazon, Google, Facebook and hundreds of others.</span>

<span style="font-weight: 400;">For anyone who does not have billions of customers there is little hope that they can collect the volume of data they need to solve problems using modern methods.  This includes academic researchers, smaller business and startups, individual working on their pet project and, ironically, open source organizations who are respectful of user privacy.</span>

&nbsp;

&nbsp;
<h2>Are privacy and training data mutually exclusive?</h2>
<span style="font-weight: 400;">This has been the Catch-22 in the open source world as we enter the machine learning era.  Privacy </span><i><span style="font-weight: 400;">is </span></i><span style="font-weight: 400;">respected, yet the basic thing needed to allow individuals to have reliable, auditable, trustworthy technologies is data.  There has been no ethical way to capture the kind and volume of data needed to allow this to be created.</span>

[/vc_column_text][vc_column_text]

&nbsp;

&nbsp;
<h3>A Cure for the Catch 22</h3>
<span style="font-weight: 400;">Here at Mycroft, we’re on the path to changing that – at least in the realm of human-machine interfaces and speech to text.  In Mycroft Core 0.8.22 we added the ability for users to select LEARN on Mark 1 devices to </span><i><span style="font-weight: 400;">choose</span></i><span style="font-weight: 400;"> to contribute recordings of their device activations to reduce false-positives (inadvertent activations) and false negatives (missed activations). Now all users can </span><i><span style="font-weight: 400;">choose</span></i><span style="font-weight: 400;"> to Opt-In to be part of the Mycroft Open Dataset and share some of their data to help us improve this technology.</span>

&nbsp;

<span style="font-weight: 400;">All who Opt-In under their basic settings at </span><a href="https://home.mycroft.ai/#/setting/basic"><span style="font-weight: 400;">https://home.mycroft.ai/#/setting/basic</span></a><span style="font-weight: 400;"> can later choose to Opt-Out, stopping not only future data contributions but also removing any previously contributed data from future datasets. We truly appreciate the help of all in building an AI for Everyone, and aim to safeguard what has been entrusted to us.</span>

&nbsp;

&nbsp;

[/vc_column_text][/vc_column][/vc_row][vc_row type="in_container" full_screen_row_position="middle" scene_position="center" text_color="dark" text_align="left" overlay_strength="0.3"][vc_column column_padding="no-extra-padding" column_padding_position="all" background_color_opacity="1" background_hover_color_opacity="1" column_shadow="none" width="5/6" tablet_text_alignment="default" phone_text_alignment="default" column_border_width="none" column_border_style="solid"][nectar_gradient_text heading_tag="h1" color="extra-color-gradient-2" gradient_direction="horizontal" text="Find the Open Data Set on our Github"][/vc_column][vc_column column_padding="no-extra-padding" column_padding_position="all" background_color_opacity="1" background_hover_color_opacity="1" column_shadow="none" width="1/6" tablet_text_alignment="default" phone_text_alignment="default" column_border_width="none" column_border_style="solid"][nectar_icon icon_family="fontawesome" icon_style="default" icon_color="black" icon_padding="20px" icon_fontawesome="fa fa-github" url="https://github.com/MycroftAI/mycroft-core/pull/1127" icon_size="70"][/vc_column][/vc_row][vc_row type="in_container" full_screen_row_position="middle" scene_position="center" text_color="dark" text_align="left" overlay_strength="0.3"][vc_column column_padding="no-extra-padding" column_padding_position="all" background_color_opacity="1" background_hover_color_opacity="1" column_shadow="none" width="1/1" tablet_text_alignment="default" phone_text_alignment="default" column_border_width="none" column_border_style="solid"][vc_column_text]
<h2></h2>
<h2></h2>
<h3>We view privacy as a basic human right and will go to significant lengths to protect it.</h3>
<span style="font-weight: 400;">We’re</span><i><span style="font-weight: 400;"> extremely</span></i><span style="font-weight: 400;"> aware that we need to protect our user's privacy. Here at Mycroft we view privacy as a basic human right and will go to significant lengths to protect it.  Before we publish any data, we plan to anonymize it securely and remove any private or personally identifiable information. How? Good question. We’re still working on the details, and won’t publish any data until then. We may use differential privacy, paid reviewers or secure sandboxes. Regardless, our goal is to make user data secure while also making it available to improve the state of the art in machine learning and conversational interfaces. </span>

&nbsp;
<h4>Our commitment to our core principles – <a href="https://mycroft.ai/f-o-s-s/">Fast, Open, Simple, Strong</a> is absolute. “Being open” is the principle that spans everything we do.</h4>
&nbsp;
<h3>Join us in building an open data, so we can build an AI that’s truly for everyone.</h3>
[/vc_column_text][/vc_column][/vc_row]